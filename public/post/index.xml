<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog | Ahmed Abdou</title>
    <link>http://localhost:1313/post/</link>
      <atom:link href="http://localhost:1313/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Blog</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Tue, 01 Apr 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_hu68170e94a17a2a43d6dcb45cf0e8e589_3079_512x512_fill_lanczos_center_3.png</url>
      <title>Blog</title>
      <link>http://localhost:1313/post/</link>
    </image>
    
    <item>
      <title>The LLMs and the reward</title>
      <link>http://localhost:1313/post/llm-reward-problem/</link>
      <pubDate>Tue, 01 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/llm-reward-problem/</guid>
      <description>&lt;p&gt;placeholder&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>TL;DR (Msc. Thesis) Benchmarking Large Language Models for Legal Case Classification at the European Court of Human Rights</title>
      <link>http://localhost:1313/post/llms-in-law/</link>
      <pubDate>Mon, 31 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/llms-in-law/</guid>
      <description>&lt;p&gt;In recent years, artificial intelligence, particularly large language models (LLMs) like GPT-4, has transformed numerous industries by automating complex tasks. But can these powerful tools reliably classify the significance of court cases—specifically at the European Court of Human Rights (ECtHR)? This was precisely the research question I tackled in my MSc thesis at the Technical University of Munich, working in the Legal NLP lab.&lt;/p&gt;
&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;p&gt;The European Convention on Human Rights (ECHR), established in 1950 in response to the horrors of World War II, represents a commitment to protecting fundamental human rights across Europe. The European Court of Human Rights (ECtHR) began operating in 1959 with a mandate to interpret and enforce the Convention&amp;rsquo;s guarantees across all member states of the Council of Europe.&lt;/p&gt;
&lt;p&gt;Over the decades, the ECHR has expanded both in reach and influence. Its jurisprudence is characterized by a dynamic interpretative approach, reflecting the principle that the Convention must be interpreted in light of contemporary conditions to ensure that protections keep pace with evolving moral and social standards. As the Court itself emphasizes:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;What gives the Convention its strength and makes it extremely modern is the way the Court interprets it: dynamically, in the light of present-day conditions.&amp;rdquo;&lt;br&gt;
— &lt;a href=&#34;https://www.echr.coe.int/documents/d/echr/Convention_Instrument_ENG&#34;&gt;The Convention, a modern instrument (Page 7)&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This concept of the Convention as a &lt;strong&gt;living instrument&lt;/strong&gt; has allowed the Court to adapt its application to modern issues that could not have been anticipated when it was first created—challenges posed by new technologies, environmental concerns, and sensitive topics such as terrorism and migration.&lt;/p&gt;
&lt;p&gt;The current case importance levels are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Key cases&lt;/strong&gt;: The most significant judgments, decisions, and advisory opinions selected by the Bureau of the Court based on their substantial legal and societal impact.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Level 1 (High Importance)&lt;/strong&gt;: Significant contributions to the development or clarification of case-law, generally or for a specific state.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Level 2 (Medium Importance)&lt;/strong&gt;: Go beyond applying existing case-law, but without major contribution to jurisprudence.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Level 3 (Low Importance)&lt;/strong&gt;: Of little legal interest—typically simple applications of case-law, friendly settlements, or strikeouts unless a particular point of interest is raised.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;methodology&#34;&gt;Methodology&lt;/h2&gt;
&lt;p&gt;To explore this, I conducted extensive experiments with six state-of-the-art LLMs across three major model families:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;OpenAI GPT Models&lt;/strong&gt;: GPT-4o and GPT-4o-mini&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Meta&amp;rsquo;s LLaMA Models&lt;/strong&gt;: LLaMA3.1-70B and LLaMA3.1-8B&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mistral Models&lt;/strong&gt;: Mistral Large and Mistral 8B&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These models were evaluated in a &lt;em&gt;zero-shot&lt;/em&gt; scenario—meaning they were not provided with specific examples of key case classifications beforehand. Instead, they relied solely on their general training to classify cases accurately. The experiments involved three different input scenarios:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Facts Only&lt;/strong&gt;: Models were provided only with factual descriptions from the cases.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Facts + Legal Reasoning (+Law)&lt;/strong&gt;: Models received both factual information and detailed court reasoning.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Facts + Legal Reasoning + Citations (+Citations)&lt;/strong&gt;: Models were also given structured analyses of relevant legal precedents cited within each case.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Additionally, I implemented and tested advanced reasoning workflows aimed at improving the models&amp;rsquo; analytical capabilities:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ReAct (Reasoning + Acting)&lt;/strong&gt;: Interleaved reasoning steps with strategic tool usage, allowing the model to iteratively refine its conclusions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;MAD.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Multi-Agent Debate&lt;/strong&gt;: Multiple instances of the same LLM debated their reasoning over multiple rounds, refining classification decisions through collaborative analysis and critique.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;key-findings&#34;&gt;Key Findings&lt;/h2&gt;
&lt;h3 id=&#34;model-performance-insights&#34;&gt;Model Performance Insights&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;results.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Performance Variability&lt;/strong&gt;: GPT-4o emerged as the top-performing model, achieving a macro-F1 score of 68.5%. However, its decisions frequently stemmed from flawed reasoning paths, raising concerns about reliability in sensitive legal contexts.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Importance of Legal Context&lt;/strong&gt;: Using facts alone led to superficial, summary-based judgments. Adding legal reasoning significantly improved accuracy.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Mixed Effects of Citations&lt;/strong&gt;: Integrating detailed citation analyses sometimes helped, but occasionally confused the models—highlighting inconsistency across different LLMs.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;workflow-enhancements&#34;&gt;Workflow Enhancements&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Agent-Based Workflows&lt;/strong&gt;: The ReAct framework showed promise by enabling more transparent and structured reasoning. Still, models often reached conclusions prematurely without fully exploiting available resources.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Debate Limitations&lt;/strong&gt;: The multi-agent debate method improved some outcomes, but agents often reinforced their initial (sometimes incorrect) beliefs rather than correcting them.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;critical-observations&#34;&gt;Critical Observations&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Evaluating Reasoning Quality&lt;/strong&gt;: Traditional evaluation metrics like accuracy and F1 scores fail to capture the nuances of legal reasoning. These metrics alone are insufficient.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Reasoning vs. Summarization&lt;/strong&gt;: While models demonstrated strong summarization skills, they often struggled to deliver meaningful legal interpretations without explicit contextual guidance.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;The findings suggest that while models can technically handle long input contexts, they don’t always benefit from them in practice.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;implications-and-future-directions&#34;&gt;Implications and Future Directions&lt;/h2&gt;
&lt;p&gt;My thesis underscores both the substantial potential—and the critical limitations—of leveraging LLMs in legal contexts. It highlights the urgent need for specialized methods and metrics that go beyond surface-level accuracy to assess the &lt;em&gt;quality&lt;/em&gt; of legal reasoning.&lt;/p&gt;
&lt;p&gt;Several promising research directions emerge:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Advanced Evaluation Frameworks&lt;/strong&gt;: Developing robust, qualitative metrics to ensure that models provide not just accurate classifications, but also sound and justifiable reasoning.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Legal Comparison Mechanisms&lt;/strong&gt;: Future models might benefit from frameworks that systematically compare new cases against precedents, identifying critical deviations that signal important jurisprudential developments.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;This work introduced a binary classification task aimed at identifying &lt;em&gt;Key Cases&lt;/em&gt; within ECtHR jurisprudence—a high-stakes application that pushes the boundaries of what current LLMs can handle in legal reasoning.&lt;/p&gt;
&lt;p&gt;Through zero-shot chain-of-thought prompting, several key trends emerged:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;GPT-4o&lt;/strong&gt; stood out for its consistent improvement when provided with richer contextual inputs, showing a clear benefit from more detailed legal information.&lt;/li&gt;
&lt;li&gt;In contrast, &lt;strong&gt;other models&lt;/strong&gt; (LLaMA and Mistral families) tended to perform best with minimal input, and their performance often deteriorated as more complex context was added—highlighting the risk of &lt;em&gt;context saturation&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;A major challenge was the &lt;strong&gt;lack of annotated reasoning ground truth&lt;/strong&gt;, making it hard to assess the quality of the models’ justifications. In many cases, models reached the &lt;em&gt;correct outcome&lt;/em&gt; but through &lt;strong&gt;incomplete or flawed logic&lt;/strong&gt;, which undermines trust in their legal applicability.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multi-agent debate&lt;/strong&gt; setup was limited by the initial round of reasoning: if the first zero-shot chain-of-thought was weak, subsequent debate rounds often failed to correct the trajectory.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Zhang, T., Kishore, V., Wu, F., Weinberger, K. Q., &amp;amp; Artzi, Y. (2019). Bertscore: Evaluating text generation with bert. arXiv preprint arXiv:1904.09675.&lt;/li&gt;
&lt;li&gt;Zha, Y., Yang, Y., Li, R., &amp;amp; Hu, Z. (2023). AlignScore: Evaluating factual consistency with a unified alignment function. arXiv preprint arXiv:2305.16739.&lt;/li&gt;
&lt;li&gt;Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M. A., Lacroix, T., &amp;hellip; &amp;amp; Lample, G. (2023). Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971.&lt;/li&gt;
&lt;li&gt;Du, Y., Li, S., Torralba, A., Tenenbaum, J. B., &amp;amp; Mordatch, I. (2023). Improving factuality and reasoning in language models through multiagent debate. arXiv preprint arXiv:2305.14325.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.echrblog.com/2025/01/reflections-on-courts-key-case-law-of.html&#34;&gt;https://www.echrblog.com/2025/01/reflections-on-courts-key-case-law-of.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Non-Causal Associations -- Reasons and Examples</title>
      <link>http://localhost:1313/post/correlation_causation/</link>
      <pubDate>Wed, 30 Dec 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/correlation_causation/</guid>
      <description>&lt;p&gt;One phrase you heard in your probability class is that correlation does not imply causation. Later, you came across the the popular association between ice-cream and drowning numbers, you instantly recall that does not mean the ice-cream is the cause of the drowning. But, how can you explain the existence of the association? In this blog post, various interpretation of the non-casual associations is listed and explained. The code snippets used are in &lt;a href=&#34;https://github.com/AhmedAbdel-Aal/DataSience-home/blob/main/non%20causal%20associations/non-causal%20relations%20-%20Induction%20of%20third%20variable.ipynb&#34;&gt;this notebook&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Lack of Statistical Support&lt;/li&gt;
&lt;li&gt;Data Fishing&lt;/li&gt;
&lt;li&gt;Reversed Interpretation&lt;/li&gt;
&lt;li&gt;Induction of third variable
&lt;ul&gt;
&lt;li&gt;Common Cause (Fork)&lt;/li&gt;
&lt;li&gt;Indirect Association (Chain)&lt;/li&gt;
&lt;li&gt;Common Consequence(Collider)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;1--lack-of-statistical-support&#34;&gt;1- Lack of Statistical Support&lt;/h2&gt;
&lt;p&gt;An association can be observed if the data points used are too few to be used in statistical test i.e, relationship existed by chance. Thus, having more data may show that the relationship between variables do not exist.&lt;/p&gt;
&lt;h2 id=&#34;1--lack-of-statistical-support-1&#34;&gt;1- Lack of Statistical Support&lt;/h2&gt;
&lt;p&gt;An association can be observed if the data points used are too few to be used in statistical test i.e, relationship existed by chance. Thus, having more data may show that the relationship between variables do not exist.&lt;/p&gt;
&lt;h2 id=&#34;2--data-fishing&#34;&gt;2- Data Fishing&lt;/h2&gt;
&lt;p&gt;Also referred to as p-hacking, data dreding, or cherry picking. This can happen when conducting large number of exploration, and testing hypothesis and only report those who shows the associations. You can take a look for various examples in spurious-correlations, and here one that shows that there is relationship between computer science doctorates and arcade revenue. While, you can&amp;rsquo;t think of logical scenario where one of these variables will be the cause of the other, this plot shows a very strong association between them. This plot is a result of data dreding, where no experiments is conducted over isolated variables against control groups. The association, maybe just by pure chance, happen to exist for the subset of data in hand.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;s1.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;3--reversed-interpretation&#34;&gt;3- Reversed Interpretation&lt;/h2&gt;
&lt;p&gt;A possible misinterpretation of the association is to reverse the cause and effect. In a study published in Nature in 1999 where the findings showed that &amp;ldquo;Small children and babies who sleep with the light on are more likely to grow up shortsighted than children who sleep in the dark&amp;rdquo; [4]. While there is no causal link starting from turning light on to have short-sightedness, a reverse link was found. It turned out that parents who shortsighted tends to leave lights on, and given the short-sightedness is genetic, the children of those parents may inherit it. So, short-sightedness is the cause and turning the light on is the effect.&lt;/p&gt;
&lt;h2 id=&#34;4--induction-of-third-variable&#34;&gt;4- Induction of third variable&lt;/h2&gt;
&lt;h3 id=&#34;41-common-cause-fork&#34;&gt;4.1 common cause (fork)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;s2.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;The common cause or fork junction, where c is the confounder of a and b. Due to c, the variables a and b will be statistically correlated. If we conditioned on c as in figure, we will block the path of association from a to b. Thus, we call a and b &amp;lsquo;conditionally independent&amp;rsquo;.&lt;/p&gt;
&lt;p&gt;Here we implement a tweaked example from [2] using the code flow used in [1]:&lt;/p&gt;
&lt;p&gt;c = age of child&lt;/p&gt;
&lt;p&gt;a = speed of ball kicked by a child&lt;/p&gt;
&lt;p&gt;b = reading ability of child&lt;/p&gt;
&lt;p&gt;The variables a and b are gaussian with mean of age_of_child and 3 x age_of_child + 5 respectively, and standard deviations of 1. This should make both a (speed of kicked ball) and b (reading ability) high with higher values of age of child. (the equations here are randomly initialized, and is not based on any facts)&lt;/p&gt;
&lt;p&gt;First we initialize the data points&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1000&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# number of data points&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;ages&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;prob_ages&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;age_of_child&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ages&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;replace&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;TRUE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prob&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prob_ages&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;speed_of_kicked_ball&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rnorm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;age_of_child&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;reading_ability&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rnorm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;age_of_child&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then, we visualize how speed of kicked ball and reading ability correlates with 0.69 degree of correlation.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;s3.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;cor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;speed_of_kicked_ball&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;reading_ability&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;[1]&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0.6955224&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Lastly, we visualize the variables again but this time conditioned on the age. To find out the correlation between the speed of kicked ball and their reading ability has almost zero correlation in each age.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;s4.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;dt[&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;.(correlation&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;cor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;speed_of_kicked_ball&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reading_ability&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;by&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;age_of_child]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       &lt;span class=&#34;n&#34;&gt;age_of_child&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;correlation&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;  &lt;span class=&#34;n&#34;&gt;age_of_child&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;9&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;-0.04682699&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;age_of_child&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;10&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;-0.04419920&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;  &lt;span class=&#34;n&#34;&gt;age_of_child&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;8&lt;/span&gt;  &lt;span class=&#34;m&#34;&gt;0.01215684&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;m&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;  &lt;span class=&#34;n&#34;&gt;age_of_child&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;7&lt;/span&gt;  &lt;span class=&#34;m&#34;&gt;0.03341457&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Thus we conclude that age of child is a common cause, that makes speed of kicked ball and reading ability correlates, while there are no causal link.&lt;/p&gt;
&lt;h3 id=&#34;42-indirect-association-chain&#34;&gt;4.2 Indirect association (chain)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;s5.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;The variable c is called the mediator, which allow the effect of a to be transmitted to b. Again, c here blocks the path from a to b. So, if c is being condition on, the correlation between a and b would disappear.&lt;/p&gt;
&lt;p&gt;Here we implement this associations by:&lt;/p&gt;
&lt;p&gt;a = motivation level to joining a gym&lt;/p&gt;
&lt;p&gt;c = either joining the gym or not&lt;/p&gt;
&lt;p&gt;b = average of muscle weight increase in the body&lt;/p&gt;
&lt;p&gt;Initializing the motivation and going to gym as binomial variables with 70% probability to be motivated and 50% to going to gym if you are motivated.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1000&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;motivation_level&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rbinom&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prob&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0.7&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;gym&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rbinom&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;motivation_level&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prob&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;muscle_weight_avg&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rnorm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gym&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;5&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;dt&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;data.table&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;motivation_level&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;factor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;motivation_level&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;muscle_weight_avg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gym&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;paste0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;went to gym = &amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;factor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;gym&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Visualizing the motivation level against the muscle average weight shows an association.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;ggplot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;aes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;motivation_level&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;muscle_weight_avg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;geom_boxplot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;s6.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;This association disappears when we condition on going to gym or not.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;ggplot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;aes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;motivation_level&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;muscle_weight_avg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;geom_boxplot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;facet_wrap&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;~&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;gym&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;s7.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;43-common-consequence-collider&#34;&gt;4.3 common consequence (Collider)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;s8.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;This is the scenario where two different variables have the same end in a causal link. Also referred to as collider.&lt;/p&gt;
&lt;p&gt;The collider scenario works in the exact opposite way to the previous scenarios, where conditioning on (observing) the variable c will connect the path and make a and b dependent.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s assume in some IT company a person become the project manager if he either very good in management or on the technical side. Maybe both, yet not necessary. This IT company observed a negative correlation between being good at management and being good at IT. However, in real life this is not the case.&lt;/p&gt;
&lt;p&gt;knowing that a person is good at management explains his way to being project manager. While, knowing a person is not very good at management, then the only other option is that he is good at IT. This negative correlation holds only because we conditioned on the person being project manager in this company. If we released this condition, we will not observe the relation anymore. This scenario is often called explain-away effect or Berkson&amp;rsquo;s paradox [5].&lt;/p&gt;
&lt;p&gt;Resources&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://gagneurlab.github.io/dataviz/graph-supported-hypos.html#correlation-and-causation&#34;&gt;https://gagneurlab.github.io/dataviz/graph-supported-hypos.html#correlation-and-causation&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;J.Pearl, D.Macakenzie, The Book of Why- chapter 3- bayesian networks: what causes say about data&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;C. Bishop, Pattern Recognition and Machine Learning- 8.2.1 Three example graphs&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Children who sleep with light on may damage their sight&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Berkson&amp;rsquo;s paradox&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cover pic. from: &lt;a href=&#34;https://www.popularmechanics.com/science/math/a27818/correlation-causality-statistics/&#34;&gt;https://www.popularmechanics.com/science/math/a27818/correlation-causality-statistics/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Triplet Loss Function for embedding space learning</title>
      <link>http://localhost:1313/post/triplet_loss_function/</link>
      <pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/triplet_loss_function/</guid>
      <description>&lt;p&gt;In this blog, a full guide for the triplet loss function that gained special attention lately for its importance in face recognition and verification tasks. The blog discuss the triplets variations and different mining techniques. Then, some advanced notes about the soft margin from &lt;a href=&#34;https://arxiv.org/pdf/1703.07737.pdf&#34;&gt;1&lt;/a&gt;, and Improved triplet loss from &lt;a href=&#34;https://openaccess.thecvf.com/content_cvpr_2016/papers/Cheng_Person_Re-Identification_by_CVPR_2016_paper.pdf&#34;&gt;2&lt;/a&gt;. Finally, the visualization of trained embeddings from the GitHub Gist &lt;a href=&#34;https://github.com/AhmedAbdel-Aal/DeepLearning_home/blob/main/Triplet%20Loss/Mnist_Embeddings_Visualization_using_Semi_Hard_Triplet_Loss.ipynb&#34;&gt;Mnist Embeddings Visualization using Semi-Hard Triplet Loss&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;table-of-contents&#34;&gt;table of contents&lt;/h2&gt;
&lt;p&gt;1- &lt;a href=&#34;#1-what-is-triplet-loss-function&#34;&gt;what is triplet loss function&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;​			- &lt;a href=&#34;#siamese-network&#34;&gt;Siamese Network&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;​			- &lt;a href=&#34;triplet-loss-definition&#34;&gt;Triplet Loss Definition&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;2- &lt;a href=&#34;#2-triplets-variation&#34;&gt;Triplets variation&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;3- &lt;a href=&#34;#3-triplets-mining-techniques&#34;&gt;Triplets mining techniques&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;4- &lt;a href=&#34;#4-advanced-notes&#34;&gt;Advanced Notes&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;​     	- &lt;a href=&#34;#soft-margin&#34;&gt;Soft margin&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;​		 - &lt;a href=&#34;#improved-triplet-loss&#34;&gt;Improved triplet loss&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;​		 - &lt;a href=&#34;#embedding-visualization&#34;&gt;Embedding visualization&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;5-&lt;a href=&#34;#5-resources&#34;&gt;Resources&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;1-what-is-triplet-loss-function&#34;&gt;1-What is Triplet Loss Function&lt;/h2&gt;
&lt;p&gt;Triplet loss is always accompanied with face recognition, verification tasks. Triplet loss allows the option of dealing with variable number of classes, as in face recognition. Face recognition is the question of &amp;ldquo;who is this person from all the persons in the data-set we have&amp;rdquo;. Triplet loss also raised with Siamese networks architecture.&lt;/p&gt;
&lt;h3 id=&#34;siamese-networks&#34;&gt;Siamese Networks&lt;/h3&gt;
&lt;p&gt;Siamese network is the type of network that have more than one instance of the same model, to learn similarities and differences between data inputs. To illustrate more, assume we want to build face recognition model, then Siamese network is a good choice, and it would work in the following manner:&lt;/p&gt;
&lt;p&gt;First of all, let&amp;rsquo;s create a model that takes an image as inputs and output an embedding of that image.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;s.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;Then let&amp;rsquo;s create two instances of that model, and pass the two corresponding embeddings into a similarity function. If the two images are of the &lt;em&gt;&lt;strong&gt;same person&lt;/strong&gt;&lt;/em&gt;, then they should have &lt;em&gt;&lt;strong&gt;high similarity&lt;/strong&gt;&lt;/em&gt;, and &lt;em&gt;&lt;strong&gt;low similarity&lt;/strong&gt;&lt;/em&gt; if the two images are of &lt;em&gt;&lt;strong&gt;different persons&lt;/strong&gt;&lt;/em&gt;. Now, we can define that the loss is the complement of the similarity.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./siamese.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;triplet-loss-definition&#34;&gt;Triplet Loss Definition&lt;/h3&gt;
&lt;p&gt;The aim of the triplet loss is to make sure of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The instances from the same class are pulled near each other&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The instances from different classes are pushed away from each other.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To explain how the previous two points are achieved by the triplet loss, let&amp;rsquo;s assume we have a neural network that works as an embedding function. Assume that, an instance from our data-set is x, and the embedding function is f(x) that result in an embeddings vector X. By the same concept, another instance y would result in Y vector after being passed through f(y). d(X,Y) is a function that calculates the distance between the two vectors X and Y. If x and y belong to the same class, then our aim is to make this distance small as possible, and the opposite otherwise.&lt;/p&gt;
&lt;p&gt;To formalize the previous requirements, we need to pick three embeddings with the following specific properties:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;anchor&lt;/strong&gt;&lt;/em&gt;, A = f(a).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;positive&lt;/strong&gt;&lt;/em&gt;, P = f(p). Another instance from the same class as the anchor.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;negative&lt;/strong&gt;&lt;/em&gt;, N = f(n). Another instance from a different class than the anchor.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That&amp;rsquo;s from where the name &amp;ldquo;triplets&amp;rdquo; came. Then, we need to minimize the distance d(A,P), and maximize the distance d(A,N). To do so:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./derivation%20without%20margin.PNG&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;The previous inequality is satisfied when the d(A,N) is bigger than the d(A,P). However, there is a trivial solution that also satisfies the equation, which is both the distances are equal to zero. To prevent the trained model from this trivial solution, a new parameter called &amp;ldquo;margin&amp;rdquo; is introduced, so that the new derivation would be like:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;derivation%20with%20margin.PNG&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;To formulate this requirement into a function, the hinge function is used. The hinge function assure that if the triplets already follow our requirements, then no loss (zero loss) is detected.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;TL.PNG&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;A practical intuition of what triplet loss do in face recognition is, if we applied the triplet loss for training the Siamese networks mentioned above, then the embeddings for two &lt;em&gt;&lt;strong&gt;different images&lt;/strong&gt;&lt;/em&gt; for the &lt;em&gt;&lt;strong&gt;same person&lt;/strong&gt;&lt;/em&gt; have a small distance between each other, and both of them having a bigger distances with the embeddings for the images of another &lt;em&gt;&lt;strong&gt;different person&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.hashnode.com/res/hashnode/image/upload/v1643160063974/QTfxpsSUB.png?auto=compress,format&amp;amp;format=webp&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;2-triplets-variation&#34;&gt;2-Triplets variation&lt;/h1&gt;
&lt;p&gt;Triplets variations means that there are more than one type of triplets that you can collect from your data. First of all, we have a base rule that defines that triplets as anchor, positive example and negative example. The variations comes when which exactly positive examples from all the positives that you can choose at each time, and which exactly the negative example that you can choose from all the negative examples that you have.&lt;/p&gt;
&lt;p&gt;according to our rule:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./TL.PNG&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;we have three kind of triplets that we can generate :&lt;/p&gt;
&lt;p&gt;- &lt;em&gt;&lt;strong&gt;Easy Triplets&lt;/strong&gt;&lt;/em&gt; these triplets results in zero loss because they are already satisfying the loss function i.e., the negative example has bigger distance than the positive example plus the margin&lt;/p&gt;
&lt;p&gt;​&lt;img src=&#34;easy-triplets.PNG&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;- &lt;em&gt;&lt;strong&gt;Semi-Hard Triplets&lt;/strong&gt;&lt;/em&gt; the negative example is not closer to the anchor more than the positive, but the negative example has smaller distance than the positive example plus the margin&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;semi-hard%20triplets.PNG&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;- &lt;em&gt;&lt;strong&gt;Hard Triplets&lt;/strong&gt;&lt;/em&gt; The nearest negative example and the farthest positive example to the anchor are chosen&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;hard%20triplets.PNG&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;3-triplets-mining-techniques&#34;&gt;3-Triplets mining techniques&lt;/h1&gt;
&lt;p&gt;Whatever the kind of triplets you have chosen to generate, you need to choose between two different generation approaches, offline and online mining. The core difference between them is, with offline mining you generate the triplets before the training process from your original data. While in online mining, you generate the triplets after passing your data through your embedding network and works on the embeddings themselves rather than the data examples. To get in more details for each approach:&lt;/p&gt;
&lt;h2 id=&#34;offline-mining&#34;&gt;Offline mining&lt;/h2&gt;
&lt;p&gt;You can assume that Offline mining approach is like a Siamese network with three instances of the same embedding network. Each one of the three networks takes the anchor, positive and negative examples respectively. After computing the embeddings from each example, we calculate the required distances, then the triplet loss.&lt;/p&gt;
&lt;p&gt;First we create list of triplets (a,p,n), whatever the type of triplets we need to generate, then we divide them into N batches. For each batch, we pass triplets one after the other, resulting in their corresponding embeddings. So we make N passes for one epoch.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;offline-mining.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;One point can be added here, is that we can update the distribution of the triplets over the N batches after each epoch.&lt;/p&gt;
&lt;p&gt;The drawbacks of this approach are :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;you need to make a full pass on the data-set before the training.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;you may need to update the mined batches after each epochs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It is not clear which of the triplets you generated are semi-hard and which are hard, because the type of triplets depends on the distance function, which in turns depends on the embedding vector.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The memory and computation constraints due to training 3 identical networks.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;online-mining&#34;&gt;Online mining&lt;/h2&gt;
&lt;p&gt;The idea of Online mining is to overcome the computation and memory drawback of the offline mining. Thus the triplets mining is applied over the embeddings of the data, not the data itself. Therefore the architecture of the model is changed into:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;offline-mining.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;First, we pass a 3N batch of input data through the embedding network to calculate 3N embedding vectors. Secondly, we create a pair-wise distance matrix for all the embedding vectors. Third, for each vector we chose a positive and negative examples to calculate the loss. Finally, we accumulate the loss from all the triplets to be out batch loss.&lt;/p&gt;
&lt;p&gt;Worth to mention that the number of valid triplets we can get from a batch depends on how the data are distributed over the batches. In best case scenario, If we passed 3N input Batch to the embedding network, we can get at most N triplets. Thus we can divide the data classes fairly over the batches before training, but this would not be the best solution in case of imbalanced data.&lt;/p&gt;
&lt;p&gt;There are two types of online triplets mining strategies introduced in &lt;a href=&#34;https://arxiv.org/pdf/1703.07737.pdf&#34;&gt;In Defense of the Triplet Loss for Person Re-Identification&lt;/a&gt;. They are named &lt;code&gt;Batch All&lt;/code&gt; and &lt;code&gt;Batch Hard&lt;/code&gt;. An implementation for the two strategies are implemented in the great blog post by Olivier Moindrot &lt;a href=&#34;https://omoindrot.github.io/&#34;&gt;Triplet Loss and Online Triplet Mining in TensorFlow&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;batch-hard&#34;&gt;Batch Hard&lt;/h3&gt;
&lt;p&gt;Select the hardest positive (farthest positive) and the hardest negative (nearest negative) for each anchor within its batch. The also have been referred by &lt;strong&gt;moderate triplets&lt;/strong&gt;, as they are the hardest but within its batch only, not over all the data-set.&lt;/p&gt;
&lt;h3 id=&#34;batch-all&#34;&gt;Batch All&lt;/h3&gt;
&lt;p&gt;Select all the possible combination of triplets (hard, and semi-hard).&lt;/p&gt;
&lt;h1 id=&#34;4-advanced-notes&#34;&gt;4-Advanced Notes&lt;/h1&gt;
&lt;h4 id=&#34;soft-margin&#34;&gt;Soft margin&lt;/h4&gt;
&lt;p&gt;Imagine a triplets where the condition  &lt;code&gt;d(A,N) &amp;gt;= d(A,P) + margin&lt;/code&gt;  is already satisfied, then according to triplet loss rule that will result in zero. The zero we got is due to the hinge function  &lt;strong&gt;F(x) = max(x,0)&lt;/strong&gt;. But, what if we want to further make the gap wider. In other words, push the negative example more farther and pull the positive example more closer.&lt;/p&gt;
&lt;p&gt;From &lt;a href=&#34;https://arxiv.org/pdf/1703.07737.pdf&#34;&gt;In Defense of the Triplet Loss for Person Re-Identification&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The role of the hinge function [m + •]+ is to avoid correcting “already correct” triplets. But in person ReID, it can be beneficial to pull together samples from the same class as much as possible&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;ReID: person re-identification.&lt;/p&gt;
&lt;p&gt;To do so, the hinge function is replaced by another function, called soft plus &lt;strong&gt;F(x) = 1+e&lt;sup&gt;x&lt;/sup&gt;&lt;/strong&gt; . This function knows as &lt;code&gt;log1p&lt;/code&gt; in numpy library. check &lt;a href=&#34;https://numpy.org/doc/stable/reference/generated/numpy.log1p.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The reason for the soft margin naming came from &lt;a href=&#34;https://arxiv.org/pdf/1703.07737.pdf&#34;&gt;In Defense of the Triplet Loss for Person Re-Identification&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.hashnode.com/res/hashnode/image/upload/v1643160392810/dOkCbm_7y.jpeg?auto=compress,format&amp;amp;format=webp&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The softplus function has similar behavior to the hinge, but it decays exponentially instead of having a hard cut-off, we hence refer to it as the soft-margin formulation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;improved-triplet-loss&#34;&gt;Improved triplet loss:&lt;/h4&gt;
&lt;p&gt;In &lt;a href=&#34;https://openaccess.thecvf.com/content_cvpr_2016/papers/Cheng_Person_Re-Identification_by_CVPR_2016_paper.pdf&#34;&gt;Person Re-Identification by Multi-Channel Parts-Based CNN with Improved Triplet Loss Function&lt;/a&gt; a new approach of calculating the triplet loss is proposed. The reason for new proposed way is to make sure that each class cover a reasonable intra-class space in the new learned space.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;instances belonging to the same person may form a large cluster with a relatively large average intra-class distance in the learned feature space. Clearly, this is not a desired outcome, and will inevitably hurt the person re-id performance.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For this reason a new margin &lt;strong&gt;m2&lt;/strong&gt; which is much smaller than the first margin &lt;strong&gt;m1&lt;/strong&gt; is used to pull the instances  of the same class more closer. The new triplet loss equation would be:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;improved%20TL.PNG&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The previous equation is from &lt;a href=&#34;https://openaccess.thecvf.com/content_cvpr_2016/papers/Cheng_Person_Re-Identification_by_CVPR_2016_paper.pdf&#34;&gt;here&lt;/a&gt;, and it is modified to match the blog notations.&lt;/p&gt;
&lt;h4 id=&#34;embedding-visualization&#34;&gt;Embedding visualization&lt;/h4&gt;
&lt;p&gt;One way to gain intuition about the pushing and pulling between the embeddings vectors is to visualize them over the training process. Usually the embedding vector is of a high dimension, for example in &lt;a href=&#34;&#34;&gt;FaceNet paper&lt;/a&gt; the embedding vector length was 128.  Hence, a dimensionality reduction technique is applied to reduce the embedding vector size to 2 or 3 dimensions. principal component analysis (&lt;strong&gt;PCA&lt;/strong&gt;) and  t-distributed stochastic neighbor embedding (&lt;strong&gt;t-SNE&lt;/strong&gt;) are the most popular ways used in high dimension vectors visualization.&lt;/p&gt;
&lt;p&gt;In this GitHub Gist &lt;a href=&#34;https://gist.github.com/AhmedAbdel-Aal/794d6f9c004bd07762975db580734a44&#34;&gt;Mnist Embeddings Visualization using Semi-Hard Triplet Loss&lt;/a&gt;, the Mnist data-set are passed through an Embedding network that is trained via &lt;a href=&#34;https://www.tensorflow.org/addons/api_docs/python/tfa/losses/TripletSemiHardLoss&#34;&gt;tensorflow addons Semi-Hard Triplet loss&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here is the architecture from the embedding network used, taken from &lt;a href=&#34;https://www.tensorflow.org/addons/api_docs/python/tfa/losses/TripletSemiHardLoss&#34;&gt;tensorflow addons Semi-Hard Triplet loss&lt;/a&gt;. One thing to highlight is the last layer in the network, which is &lt;strong&gt;L2_norm&lt;/strong&gt; layer. This layer is added so that the Euclidian norm of the embedding vector is 1. This in turn forces the embeddings to be on a hypersphere.&lt;/p&gt;
&lt;p&gt;From &lt;a href=&#34;https://arxiv.org/pdf/1503.03832.pdf&#34;&gt;FaceNet&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Additionally, we constrain this embedding to live on the d-dimensional hypersphere, i.e. |f(x)|&lt;sub&gt;2&lt;/sub&gt; = 1.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;embedding_network = tf.keras.Sequential([
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding=&amp;#39;same&amp;#39;, activation=&amp;#39;relu&amp;#39;, input_shape=input_shape),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        tf.keras.layers.MaxPooling2D(pool_size=2),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        tf.keras.layers.Dropout(0.3),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding=&amp;#39;same&amp;#39;, activation=&amp;#39;relu&amp;#39;),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        tf.keras.layers.MaxPooling2D(pool_size=2),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        tf.keras.layers.Dropout(0.3),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        tf.keras.layers.Flatten(),
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        tf.keras.layers.Dense(embedding_size, activation=None), # No activation on final dense layer
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ])
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Two principal components of these embedding vectors are then visualized before and after training.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;before-after.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;p&gt;Also the embeddings are plotted before each epoch to monitor how the triplet-loss affects the embeddings of the same class to be pulled towards each other, and the dissimilar classes to be pushed away from each other.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;Embeddings_over_training.gif&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;5-resources&#34;&gt;5-Resources&lt;/h1&gt;
&lt;p&gt;1-  &lt;a href=&#34;https://arxiv.org/pdf/1703.07737.pdf&#34;&gt;In Defense of the Triplet Loss for Person Re-Identification&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;2- &lt;a href=&#34;https://openaccess.thecvf.com/content_cvpr_2016/papers/Cheng_Person_Re-Identification_by_CVPR_2016_paper.pdf&#34;&gt;Person Re-Identification by Multi-Channel Parts-Based CNN with Improved Triplet Loss Function&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;3- Blog post by Olivier Moindrot &lt;a href=&#34;https://omoindrot.github.io/&#34;&gt;Triplet Loss and Online Triplet Mining in TensorFlow&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;4- Blog post Brandon Amos &lt;a href=&#34;http://bamos.github.io/2016/01/19/openface-0.2.0/&#34;&gt;OpenFace 0.2.0: Higher accuracy and halved execution time&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;5- &lt;a href=&#34;https://arxiv.org/pdf/1503.03832.pdf&#34;&gt;FaceNet: A Unified Embedding for Face Recognition and Clustering&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;6- &lt;a href=&#34;https://www.tensorflow.org/addons/api_docs/python/tfa/losses/TripletSemiHardLoss&#34;&gt;tensorflow addons Semi-Hard Triplet loss&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
